{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Preprocessing Project\n",
            "### Dataset: Spaceship-titanic\n",
            "---\n",
            "#### Authors:\n",
            "- Dawid Siera\n",
            "- Anatol Kaczmarek\n",
            "- Deniz Aksoy\n",
            "- Marcin Leszczy≈Ñski\n",
            "---"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Let's start with our preprocessing. In preprocessing library we use `pandas.DataFrame` class as a base as it's very popular and commonly used when working with data. So let's start by importing pandas and preprocessing."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 15,
         "metadata": {},
         "outputs": [],
         "source": [
            "import pandas as pd\n",
            "import preprocessing as pr"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Now it's time to load our dataset. From now on we will work with `spaceship-titanic` dataset as it was main objective of our assignment. For this code to work, you need to download dataset and save the same directory as this notebook or you can just provide absolute path."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "metadata": {},
         "outputs": [],
         "source": [
            "dataset = pd.read_csv('spaceship-titanic/train.csv')"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Now we can check how good raw dataset works on classifier implementation (test set will be chosen randomly from part of main dataset). To evaluate our dataset we need to create instance of `pr.benchmarks.ClassifierBenchmark` and call it's `pr.benchmarks.ClassifierBenchmark.evaluate` method. The method will output the accuracy, so our objective will be to maximize it. If you  just want to get value you can turn printing off in classifier constructor as an argument."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 17,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "              precision    recall  f1-score   support\n",
                  "\n",
                  "       False       0.84      0.69      0.76      1284\n",
                  "        True       0.75      0.88      0.81      1324\n",
                  "\n",
                  "    accuracy                           0.79      2608\n",
                  "   macro avg       0.80      0.79      0.78      2608\n",
                  "weighted avg       0.79      0.79      0.78      2608\n",
                  "\n",
                  "Accuracy before preprocessing: 78.64%\n"
               ]
            }
         ],
         "source": [
            "clf = pr.benchmarks.ClassifierBenchmark(printing=True)\n",
            "score = clf.evaluate(dataset, target='Transported')\n",
            "print(f'Accuracy before preprocessing: {score*100:.2f}%')"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Now to take full advantage of our library we will choose our selector and extractor. So far there is only one selector implemented - `VARSelector`, so that's the one that we will use. When it comes to extractor we have two options: `PCAExtractor` and `LDAExtractor`. For our dataset, `LDAExtractor` will not be recommended as it tries to classify into many groups, it can be used, but the results weren't any close to the `PCAExtractor` or even to pure dataset, so we will go with `PCAExtractor`."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 18,
         "metadata": {},
         "outputs": [],
         "source": [
            "selector = pr.VARSelector()\n",
            "extractor = pr.PCAExtractor(num_components=8, target='Transported')"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Now we will choose combine these two with additional encoding and na handling methods. For any dataset there exists class `pr.Preprocessing`, but our state-of-the-art version for this dataset is `pr.SpaceShipPreprocessing` which inherits from `pr.Preprocessing` and  implements additional splitting features method, which has some hard-coded values to work better with our dataset."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 19,
         "metadata": {
            "ExecuteTime": {
               "end_time": "2024-04-23T22:34:03.091414Z",
               "start_time": "2024-04-23T22:34:01.642296Z"
            }
         },
         "outputs": [],
         "source": [
            "preprocessing = pr.SpaceShipPreprocessing(dataset, target='Transported',\n",
            "                                 selector=selector, extractor=extractor)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "To run the final combination we need to call method `pr.Preprocessing.preprocess()`"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 20,
         "metadata": {},
         "outputs": [],
         "source": [
            "new_dataset = preprocessing.preprocess()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Now let's evaluate our dataset again"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 21,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "              precision    recall  f1-score   support\n",
                  "\n",
                  "         0.0       0.83      0.73      0.78      1284\n",
                  "         1.0       0.77      0.85      0.81      1324\n",
                  "\n",
                  "    accuracy                           0.79      2608\n",
                  "   macro avg       0.80      0.79      0.79      2608\n",
                  "weighted avg       0.80      0.79      0.79      2608\n",
                  "\n",
                  "Accuracy after preprocessing: 79.22%\n"
               ]
            }
         ],
         "source": [
            "score = clf.evaluate(new_dataset, target='Transported')\n",
            "print(f'Accuracy after preprocessing: {score*100:.2f}%')"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "If everything will work as it is supposed to, the accuracy should increase, which should prove that our preprocessing gave positive results :D"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3 (ipykernel)",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.7"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
